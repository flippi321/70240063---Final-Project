 ---------- Done ---------- 
• Get Hadoop working (Use GFS)
• Query the top-5 articles with articles details (text, image, and video if existing) (involving the join of Be-Read table and Article table)
    - daily
    - weekly
    - monthly
    - Custom duration?
• Implement Insert function that automatically allocates data to right DBMS
• "Populate the empty Be-Read table by inserting newly computed records into the Be-Read table."
• Implement JOIN functions between tables
    - Both with and without arguments
• Seperate Be-Read into fragments
• Implement Monitoring of DBMS containers, showing
    - Managed data (amount and location)
    - Workload
    - etc. 
• Optimize Be-Read
    - Should read from the read.dat, not from the database
• STRESS TEST
    - No bugs
    - No visually slow sections
• GUI
    - At least use Tabulate in console
• Clean data_generation, db_setup and dbms_utils
    • Proper error handling
    • Clean up setup console logs

 ---------- In Progress ---------- 
 
Jakob:
• Figure out JOIN situation
    - Make sure JOIN-query can be without any conditions
• Implement updates to Be-Read after Read changes

Chriss:
• Get actual replica consideration in our DMBS
    - Try to get it to work.
    - If it doesn't, we either A gaslight or B girlboss (Go to non-replicated version)
• Distribute science Articles over both databases
    - Right now it's just given to one  
    - Mabye have dynamic allocation, where we add by id or smt?
    - If not, we just randomly allocate