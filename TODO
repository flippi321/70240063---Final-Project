 ---------- Done ---------- 
• Get Hadoop working (Use GFS)
• Query the top-5 articles with articles details (text, image, and video if existing) (involving the join of Be-Read table and Article table)
    - daily
    - weekly
    - monthly
    - Custom duration?
• Implement Insert function that automatically allocates data to right DBMS
• "Populate the empty Be-Read table by inserting newly computed records into the Be-Read table."
• Implement JOIN functions between tables
    - Both with and without arguments
• Seperate Be-Read into fragments
• Implement Monitoring of DBMS containers, showing
    - Managed data (amount and location)
    - Workload
    - etc. 

 ---------- In Progress ---------- 
 
Jakob:
• Figure out JOIN situation

Chriss:
• Implement updates to Be-Read after Read changes
• Get actual replica consideration in our DMBS

 ---------- Tomorrow ---------- 
 
Jakob:
• Distribute science Articles over both databases
    - Right now it's just given to one  
    - Mabye have dynamic allocation, where we add by id or smt?
    - If not, we just randomly allocate

Chriss:
• Make sure queries can be without any conditions

 ---------- Not Done nor Planned ---------- 
• Clean data_generation
• Clean db_setup
• Clean dbms_utils

• Proper error handling

• Clean up setup console logs

• Optimize Be-Read
    - Should read from the read.dat, not from the database

• Caching

• Remove requirement that all utils commands need databases as param

• STRESS TEST
    - No bugs
    - No visually slow sections

 ---------- (Optional) advanced functions  ---------- 
• GUI
    - At least use Tabulate in console

• Hot/ Cold Standby DBMSs for fault tolerance
• Expansion at the DBMS-level allowing a new DBMS server to join
• Dropping a DBMS server at will
• Data migration from one data center to others